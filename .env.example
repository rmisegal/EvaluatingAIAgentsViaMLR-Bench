# LLM Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama2

# Optional: External LLM APIs (not required for basic usage)
# ANTHROPIC_API_KEY=your_key_here
# OPENAI_API_KEY=your_key_here

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/mlr_bench.log

# Paths
DATA_DIR=data
RESULTS_DIR=results
WORKSPACES_DIR=workspaces
